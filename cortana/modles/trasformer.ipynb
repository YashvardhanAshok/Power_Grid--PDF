{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning C:\\...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 61\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetadata saved to file_metadata.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 61\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 52\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m drive \u001b[38;5;129;01min\u001b[39;00m drives:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScanning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdrive\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m     all_metadata\u001b[38;5;241m.\u001b[39mextend(\u001b[43mscan_drive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrive\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_metadata.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     55\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(all_metadata, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 42\u001b[0m, in \u001b[0;36mscan_drive\u001b[1;34m(drive)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m files \u001b[38;5;241m+\u001b[39m dirs:\n\u001b[0;32m     41\u001b[0m         file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, name)\n\u001b[1;32m---> 42\u001b[0m         metadata\u001b[38;5;241m.\u001b[39mappend(\u001b[43mget_file_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metadata\n",
      "Cell \u001b[1;32mIn[1], line 26\u001b[0m, in \u001b[0;36mget_file_metadata\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_file_metadata\u001b[39m(file_path):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 26\u001b[0m         stat \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(file_path)\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(file_path),\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(file_path) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(file_path),\n\u001b[0;32m     31\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated_date\u001b[39m\u001b[38;5;124m\"\u001b[39m: datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mfromtimestamp(stat\u001b[38;5;241m.\u001b[39mst_ctime)\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     32\u001b[0m         }\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import platform\n",
    "import datetime\n",
    "\n",
    "\n",
    "def get_drives():\n",
    "    system = platform.system()\n",
    "    drives = []\n",
    "    if system == \"Windows\":\n",
    "        import string\n",
    "        from ctypes import windll\n",
    "\n",
    "        bitmask = windll.kernel32.GetLogicalDrives()\n",
    "        for letter in string.ascii_uppercase:\n",
    "            if bitmask & 1:\n",
    "                drives.append(f\"{letter}:\\\\\")\n",
    "            bitmask >>= 1\n",
    "    elif system == \"Linux\" or system == \"Darwin\":  # macOS\n",
    "        drives.append(\"/\")\n",
    "    return drives\n",
    "\n",
    "\n",
    "def get_file_metadata(file_path):\n",
    "    try:\n",
    "        stat = os.stat(file_path)\n",
    "        return {\n",
    "            \"file\": os.path.basename(file_path),\n",
    "            \"file_type\": \"Directory\" if os.path.isdir(file_path) else \"File\",\n",
    "            \"location\": os.path.abspath(file_path),\n",
    "            \"created_date\": datetime.datetime.fromtimestamp(stat.st_ctime).strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"file\": file_path, \"error\": str(e)}\n",
    "\n",
    "\n",
    "def scan_drive(drive):\n",
    "    metadata = []\n",
    "    for root, dirs, files in os.walk(drive):\n",
    "        for name in files + dirs:\n",
    "            file_path = os.path.join(root, name)\n",
    "            metadata.append(get_file_metadata(file_path))\n",
    "    return metadata\n",
    "\n",
    "\n",
    "def main():\n",
    "    all_metadata = []\n",
    "    drives = get_drives()\n",
    "    \n",
    "    for drive in drives:\n",
    "        print(f\"Scanning {drive}...\")\n",
    "        all_metadata.extend(scan_drive(drive))\n",
    "\n",
    "    with open(\"file_metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_metadata, f, indent=4)\n",
    "\n",
    "    print(\"Metadata saved to file_metadata.json\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "json to sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata saved to file_metadata.db\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def load_json():\n",
    "    with open(\"file_metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def sanitize_text(text):\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    return text.encode(\"utf-8\", \"ignore\").decode(\"utf-8\")\n",
    "\n",
    "def save_to_sqlite(data):\n",
    "    conn = sqlite3.connect(\"file_metadata.db\")\n",
    "    conn.execute(\"PRAGMA busy_timeout = 5000\")  # Wait up to 5 seconds\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''CREATE TABLE IF NOT EXISTS files (\n",
    "                        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                        file TEXT,\n",
    "                        file_type TEXT,\n",
    "                        location TEXT,\n",
    "                        created_date TEXT\n",
    "                    )''')\n",
    "    for entry in data:\n",
    "        cursor.execute(\"INSERT INTO files (file, file_type, location, created_date) VALUES (?, ?, ?, ?)\",\n",
    "                       (sanitize_text(entry.get(\"file\")), \n",
    "                        sanitize_text(entry.get(\"file_type\")), \n",
    "                        sanitize_text(entry.get(\"location\")), \n",
    "                        sanitize_text(entry.get(\"created_date\"))))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"Metadata saved to file_metadata.db\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    data = load_json()\n",
    "    save_to_sqlite(data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Files found:\n",
      "File: YASHVARDHAN ASHOK (1).pdf, Location: D:\\downloads\\YASHVARDHAN ASHOK (1).pdf\n",
      "File: YASHVARDHAN ASHOK (2).pdf, Location: D:\\downloads\\YASHVARDHAN ASHOK (2).pdf\n",
      "File: Yashvardhan Ashok Letter (1).pdf, Location: D:\\downloads\\Yashvardhan Ashok Letter (1).pdf\n",
      "File: Yashvardhan Ashok Letter (2).pdf, Location: D:\\downloads\\Yashvardhan Ashok Letter (2).pdf\n",
      "File: Yashvardhan Ashok Letter.pdf, Location: D:\\downloads\\Yashvardhan Ashok Letter.pdf\n",
      "File: Yashvardhan Ashok Resume - 1 (1).pdf, Location: D:\\downloads\\Yashvardhan Ashok Resume - 1 (1).pdf\n",
      "File: Yashvardhan Ashok Resume - 1 (2).pdf, Location: D:\\downloads\\Yashvardhan Ashok Resume - 1 (2).pdf\n",
      "File: Yashvardhan Ashok Resume - 1.pdf, Location: D:\\downloads\\Yashvardhan Ashok Resume - 1.pdf\n",
      "File: Yashvardhan Ashok Resume - 2.pdf, Location: D:\\downloads\\Yashvardhan Ashok Resume - 2.pdf\n",
      "File: YASHVARDHAN ASHOK.pdf, Location: D:\\downloads\\YASHVARDHAN ASHOK.pdf\n",
      "File: YashvardhanAshokResume.pdf, Location: D:\\downloads\\YashvardhanAshokResume.pdf\n",
      "File: YASHVARDHAN ASHOK135619.pdf, Location: D:\\ENTERTERMENT\\coding\\testing\\bot\\cortana\\resume\\sandbox\\log\\YASHVARDHAN ASHOK135619.pdf\n",
      "File: YASHVARDHAN ASHOK143024.pdf, Location: D:\\ENTERTERMENT\\coding\\testing\\bot\\cortana\\resume\\sandbox\\log\\YASHVARDHAN ASHOK143024.pdf\n",
      "File: YASHVARDHAN ASHOK143035.pdf, Location: D:\\ENTERTERMENT\\coding\\testing\\bot\\cortana\\resume\\sandbox\\log\\YASHVARDHAN ASHOK143035.pdf\n",
      "File: YASHVARDHAN ASHOK143053.pdf, Location: D:\\ENTERTERMENT\\coding\\testing\\bot\\cortana\\resume\\sandbox\\log\\YASHVARDHAN ASHOK143053.pdf\n",
      "File: YASHVARDHAN ASHOK143241.pdf, Location: D:\\ENTERTERMENT\\coding\\testing\\bot\\cortana\\resume\\sandbox\\log\\YASHVARDHAN ASHOK143241.pdf\n",
      "File: YASHVARDHAN ASHOK14350.pdf, Location: D:\\ENTERTERMENT\\coding\\testing\\bot\\cortana\\resume\\sandbox\\log\\YASHVARDHAN ASHOK14350.pdf\n",
      "File: YASHVARDHAN ASHOK15833.pdf, Location: D:\\ENTERTERMENT\\coding\\testing\\bot\\cortana\\resume\\sandbox\\log\\YASHVARDHAN ASHOK15833.pdf\n",
      "File: YASHVARDHAN ASHOK161813.pdf, Location: D:\\ENTERTERMENT\\coding\\testing\\bot\\cortana\\resume\\sandbox\\log\\YASHVARDHAN ASHOK161813.pdf\n",
      "File: YASHVARDHAN ASHOK21651.pdf, Location: D:\\ENTERTERMENT\\coding\\testing\\bot\\cortana\\resume\\sandbox\\log\\YASHVARDHAN ASHOK21651.pdf\n",
      "File: YASHVARDHAN ASHOK22225.pdf, Location: D:\\ENTERTERMENT\\coding\\testing\\bot\\cortana\\resume\\sandbox\\log\\YASHVARDHAN ASHOK22225.pdf\n",
      "File: YASHVARDHAN ASHOK24543.pdf, Location: D:\\ENTERTERMENT\\coding\\testing\\bot\\cortana\\resume\\sandbox\\log\\YASHVARDHAN ASHOK24543.pdf\n",
      "File: YASHVARDHAN ASHOK2835.pdf, Location: D:\\ENTERTERMENT\\coding\\testing\\bot\\cortana\\resume\\sandbox\\log\\YASHVARDHAN ASHOK2835.pdf\n",
      "File: YASHVARDHAN ASHOK (1).pdf, Location: D:\\ENTERTERMENT\\coding\\testing\\bot\\friday\\Front End\\YASHVARDHAN ASHOK (1).pdf\n",
      "File: Yashvardhan Ashok (2).pdf, Location: D:\\ENTERTERMENT\\College\\certificate\\cv\\Yashvardhan Ashok (2).pdf\n",
      "File: Yashvardhan Ashok Resume.pdf, Location: D:\\ENTERTERMENT\\College\\GRE\\Yashvardhan Ashok Resume.pdf\n",
      "File: YASHVARDHAN ASHOK - W1.pdf, Location: D:\\ENTERTERMENT\\job\\YASHVARDHAN ASHOK - W1.pdf\n",
      "File: YASHVARDHAN ASHOK - W2.pdf, Location: D:\\ENTERTERMENT\\job\\YASHVARDHAN ASHOK - W2.pdf\n",
      "File: Yashvardhan Ashok Resume - 1.pdf, Location: D:\\ENTERTERMENT\\job\\Yashvardhan Ashok Resume - 1.pdf\n",
      "File: Yashvardhan Ashok Resume - 2.pdf, Location: D:\\ENTERTERMENT\\job\\Yashvardhan Ashok Resume - 2.pdf\n",
      "File: YASHVARDHAN ASHOK.pdf, Location: D:\\ENTERTERMENT\\job\\YASHVARDHAN ASHOK.pdf\n",
      "File: YASHVARDHAN ASHOK.pdf, Location: D:\\ENTERTERMENT\\job\\ats\\YASHVARDHAN ASHOK.pdf\n",
      "File: YASHVARDHAN ASHOK.pdf, Location: D:\\ENTERTERMENT\\job\\ats\\new\\YASHVARDHAN ASHOK.pdf\n",
      "File: YASHVARDHAN ASHOK1.pdf, Location: D:\\ENTERTERMENT\\job\\ats\\new\\YASHVARDHAN ASHOK1.pdf\n",
      "File: YASHVARDHAN ASHOK2.pdf, Location: D:\\ENTERTERMENT\\job\\ats\\new\\YASHVARDHAN ASHOK2.pdf\n",
      "File: YASHVARDHAN ASHOK - try.pdf, Location: D:\\ENTERTERMENT\\job\\try\\YASHVARDHAN ASHOK - try.pdf\n",
      "File: Yashvardhan Ashok (1)-1.pdf, Location: D:\\pixle old data\\com.whatsapp\\WhatsApp\\Media\\WhatsApp Documents\\Sent\\Yashvardhan Ashok (1)-1.pdf\n",
      "File: Yashvardhan Ashok (1).pdf, Location: D:\\pixle old data\\com.whatsapp\\WhatsApp\\Media\\WhatsApp Documents\\Sent\\Yashvardhan Ashok (1).pdf\n",
      "File: Yashvardhan Ashok (2).pdf, Location: D:\\pixle old data\\com.whatsapp\\WhatsApp\\Media\\WhatsApp Documents\\Sent\\Yashvardhan Ashok (2).pdf\n",
      "File: Yashvardhan Ashok (5).pdf, Location: D:\\pixle old data\\com.whatsapp\\WhatsApp\\Media\\WhatsApp Documents\\Sent\\Yashvardhan Ashok (5).pdf\n",
      "File: Yashvardhan Ashok CV.pdf, Location: D:\\pixle old data\\com.whatsapp\\WhatsApp\\Media\\WhatsApp Documents\\Sent\\Yashvardhan Ashok CV.pdf\n",
      "File: Yashvardhan Ashok Resume (4).pdf, Location: D:\\pixle old data\\com.whatsapp\\WhatsApp\\Media\\WhatsApp Documents\\Sent\\Yashvardhan Ashok Resume (4).pdf\n",
      "File: Yashvardhan Ashok Resume - 1-1.pdf, Location: D:\\pixle old data\\com.whatsapp\\WhatsApp\\Media\\WhatsApp Documents\\Sent\\Yashvardhan Ashok Resume - 1-1.pdf\n",
      "File: Yashvardhan Ashok Resume - 1.pdf, Location: D:\\pixle old data\\com.whatsapp\\WhatsApp\\Media\\WhatsApp Documents\\Sent\\Yashvardhan Ashok Resume - 1.pdf\n",
      "File: Yashvardhan Ashok Resume - 2-1.pdf, Location: D:\\pixle old data\\com.whatsapp\\WhatsApp\\Media\\WhatsApp Documents\\Sent\\Yashvardhan Ashok Resume - 2-1.pdf\n",
      "File: Yashvardhan Ashok Resume - 2.pdf, Location: D:\\pixle old data\\com.whatsapp\\WhatsApp\\Media\\WhatsApp Documents\\Sent\\Yashvardhan Ashok Resume - 2.pdf\n",
      "File: Yashvardhan Ashok Resume.pdf, Location: D:\\pixle old data\\com.whatsapp\\WhatsApp\\Media\\WhatsApp Documents\\Sent\\Yashvardhan Ashok Resume.pdf\n",
      "File: Yashvardhan Ashok-1.pdf, Location: D:\\pixle old data\\com.whatsapp\\WhatsApp\\Media\\WhatsApp Documents\\Sent\\Yashvardhan Ashok-1.pdf\n",
      "File: Yashvardhan Ashok-2.pdf, Location: D:\\pixle old data\\com.whatsapp\\WhatsApp\\Media\\WhatsApp Documents\\Sent\\Yashvardhan Ashok-2.pdf\n",
      "File: Yashvardhan Ashok-3.pdf, Location: D:\\pixle old data\\com.whatsapp\\WhatsApp\\Media\\WhatsApp Documents\\Sent\\Yashvardhan Ashok-3.pdf\n",
      "File: Yashvardhan Ashok-4.pdf, Location: D:\\pixle old data\\com.whatsapp\\WhatsApp\\Media\\WhatsApp Documents\\Sent\\Yashvardhan Ashok-4.pdf\n",
      "File: Yashvardhan Ashok-5.pdf, Location: D:\\pixle old data\\com.whatsapp\\WhatsApp\\Media\\WhatsApp Documents\\Sent\\Yashvardhan Ashok-5.pdf\n",
      "File: YASHVARDHAN ASHOK-6.pdf, Location: D:\\pixle old data\\com.whatsapp\\WhatsApp\\Media\\WhatsApp Documents\\Sent\\YASHVARDHAN ASHOK-6.pdf\n",
      "File: Yashvardhan Ashok.pdf, Location: D:\\pixle old data\\com.whatsapp\\WhatsApp\\Media\\WhatsApp Documents\\Sent\\Yashvardhan Ashok.pdf\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def find_pdf_files_by_name(search_name, file_format):\n",
    "    conn = sqlite3.connect(\"file_metadata.db\")\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Corrected SQL query\n",
    "    cursor.execute(\n",
    "        \"SELECT file, location FROM files WHERE file LIKE ? AND file LIKE ?\",\n",
    "        (f\"%{search_name}%\", f\"%{file_format}\")\n",
    "    )\n",
    "    \n",
    "    results = cursor.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    pdf_files = [f\"File: {row[0]}, Location: {row[1]}\" for row in results]\n",
    "    \n",
    "    if pdf_files:\n",
    "        print(\"PDF Files found:\")\n",
    "        for file in pdf_files:\n",
    "            print(file)\n",
    "    else:\n",
    "        print(\"No PDF files found with the given name.\")\n",
    "\n",
    "# Example usage\n",
    "search_name = \"yashvardhan\"\n",
    "file_format = \".pdf\" \n",
    "search_list = find_pdf_files_by_name(search_name, file_format)\n",
    "print(search_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ENTERTERMENT\\coding\\testing\\Power_Grid(PDF)\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and stored: YASHVARDHAN ASHOK.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pypdf\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize ChromaDB and Sentence Transformer\n",
    "chroma_client = chromadb.PersistentClient(path=\"vector_db\")\n",
    "collection = chroma_client.get_or_create_collection(\"pdf_embeddings\")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def find_pdf_files_by_name(search_name, file_format=\".pdf\"):\n",
    "    conn = sqlite3.connect(\"file_metadata.db\")\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(\n",
    "        \"SELECT file, location FROM files WHERE file LIKE ? AND file LIKE ?\",\n",
    "        (f\"%{search_name}%\", f\"%{file_format}\")\n",
    "    )\n",
    "    \n",
    "    results = cursor.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    pdf_list = [(row[0], row[1]) for row in results]\n",
    "    return pdf_list\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            reader = pypdf.PdfReader(f)\n",
    "            text = \" \".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {pdf_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_pdfs():\n",
    "    search_name = \"yashvardhan\"\n",
    "    pdf_files = find_pdf_files_by_name(search_name)\n",
    "\n",
    "    for file_name, file_path in pdf_files:\n",
    "        if os.path.exists(file_path):\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "            if text:\n",
    "                embedding = model.encode(text).tolist()\n",
    "                collection.add(documents=[text], embeddings=[embedding], ids=[file_name])\n",
    "                print(f\"Processed and stored: {file_name}\")\n",
    "        else:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "\n",
    "process_pdfs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student mentioned in the text, who is currently interning at MyUpchar, has over two years of experience in web development, data analysis, and automation. They have a strong proficiency in Python, Ruby on Rails, React, and MySQL, complemented by their skills in data visualization. Their focus is on innovative projects that improve workflows and drive decision-making through their expertise in applying data analysis techniques to improve processes. The student's internship at MyUpchar has focused on creating an offline-compatible Gmail-like internal communication system and improving message retrieval speed by 30%, streamlining messaging capabilities, reducing annual operational costs by 25%, and eliminating dependency on Google Workspace to reduce operational costs. In addition, they have created a Python-based GUI application integrated with Zebra Mail Server for automated management of over 3,000 emails daily, improved communication efficiency by 60% through real-time tracking via a dashboard, streamlined HTML-based communication and record-keeping, and automated record-keeping. The student has also developed several automation tools including TOKUMEI and ATF to reduce costs and improve business processes through innovative projects like cost reduction and process improvement, as well as reducing operational costs by 40%.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer  \n",
    "\n",
    "\n",
    "# Initialize ChromaDB\n",
    "chroma_client = chromadb.PersistentClient(path=\"vector_db\")\n",
    "collection = chroma_client.get_collection(\"pdf_embeddings\")\n",
    "\n",
    "def query_pdf_database(query):\n",
    "    # model = SentenceTransformer(\"all-MiniLM-L6-v2\") model selection\n",
    "    query_embedding = model.encode(query).tolist()  \n",
    "    results = collection.query(query_embeddings=[query_embedding], n_results=3)\n",
    "    return results[\"documents\"][0] if results[\"documents\"] else \"No relevant documents found.\"\n",
    "\n",
    "def chat_with_tinyllama(query):\n",
    "    relevant_docs = query_pdf_database(query)\n",
    "    \n",
    "    if isinstance(relevant_docs, list):\n",
    "        relevant_docs = \"\\n\".join(relevant_docs)  \n",
    "    \n",
    "    response = ollama.chat(model=\"tinyllama:latest\", messages=[{\"role\": \"user\", \"content\": relevant_docs}])\n",
    "    return response[\"message\"][\"content\"]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # user_query = input(\"Ask a question:\")\n",
    "    user_query = \"what his epectise\"\n",
    "    print(chat_with_tinyllama(user_query))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
